{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4113422c",
   "metadata": {},
   "source": [
    "                                WHAT IS WEB SCRAPING ?\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e63274",
   "metadata": {},
   "source": [
    "                                HOW WEB SCRAPERS WORK?\n",
    "Web Scrapers can extract all the data on particular sites or the specific data that a user wants. Ideally, it’s best if you specify the data you want so that the web scraper only extracts that data quickly. For example, you might want to scrape an Amazon page for the types of juicers available, but you might only want the data about the models of different juicers and not the customer reviews. \n",
    "\n",
    "So, when a web scraper needs to scrape a site, first the URLs are provided. Then it loads all the HTML code for those sites and a more advanced scraper might even extract all the CSS and Javascript elements as well. Then the scraper obtains the required data from this HTML code and outputs this data in the format specified by the user. Mostly, this is in the form of an Excel spreadsheet or a CSV file, but the data can also be saved in other formats, such as a JSON file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b7733",
   "metadata": {},
   "source": [
    "                          DIFFERENT TYPES OF WEB SCRAPERS--\n",
    "Web Scrapers can be divided on the basis of many different criteria, including Self-built or Pre-built Web Scrapers, Browser extension or Software Web Scrapers, and Cloud or Local Web Scrapers.\n",
    "\n",
    "You can have Self-built Web Scrapers but that requires advanced knowledge of programming. And if you want more features in your Web Scraper, then you need even more knowledge. On the other hand, pre-built Web Scrapers are previously created scrapers that you can download and run easily. These also have more advanced options that you can customize.\n",
    "\n",
    "Browser extensions Web Scrapers are extensions that can be added to your browser. These are easy to run as they are integrated with your browser, but at the same time, they are also limited because of this. Any advanced features that are outside the scope of your browser are impossible to run on Browser extension Web Scrapers. But Software Web Scrapers don’t have these limitations as they can be downloaded and installed on your computer. These are more complex than Browser web scrapers, but they also have advanced features that are not limited by the scope of your browser.\n",
    "Cloud Web Scrapers run on the cloud, which is an off-site server mostly provided by the company that you buy the scraper from. These allow your computer to focus on other tasks as the computer resources are not required to scrape data from websites. Local Web Scrapers, on the other hand, run on your computer using local resources. So, if the Web scrapers require more CPU or RAM, then your computer will become slow and not be able to perform other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a4746",
   "metadata": {},
   "source": [
    "                                 WHAT IS WEB SCRAPING IS USED FOR ?\n",
    "\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "\n",
    "5. Email Marketing\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c0ac3",
   "metadata": {},
   "source": [
    "                     Why is Python a popular programming language for WEB SCRAPING ?\n",
    "Python seems to be in fashion these days! It is the most popular language for web scraping as it can handle most of the processes easily. It also has a variety of libraries that were created specifically for Web Scraping. Scrapy is a very popular open-source web crawling framework that is written in Python. It is ideal for web scraping as well as extracting data using APIs. Beautiful soup is another Python library that is highly suitable for Web Scraping. It creates a parse tree that can be used to extract data from HTML on a website. Beautiful soup also has multiple features for navigation, searching, and modifying these parse trees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ba6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec464b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://codewithharry.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a17df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce17326",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlcontent = r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a75776",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(htmlcontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(htmlcontent,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53121502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4daf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find[class]) #get class of any element in the html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all('p',class_=\"lead\")) # find all the elements with class lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('p').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc84ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = soup.find_all('a')3get all anchor tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c408938",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in anchors:\n",
    "    linktext = \"https://codewithharry.com\"+link.get('href')\n",
    "    all_links.add(link)\n",
    "    print(linktext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e201b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
